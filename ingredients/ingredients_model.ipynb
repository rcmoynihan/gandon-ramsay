{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIS 285N Cognitive Computing<br>\n",
    "Final Project<br>\n",
    "Jerry Che - Jose Guerrero - Riley Moynihan - Noah Placke - Sarah Teng - Palmer Wenzel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredients Generation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following techniques from:\n",
    "- https://towardsdatascience.com/generative-adversarial-networks-in-python-73d3972823d3\n",
    "- https://www.maskaravivek.com/post/gan-synthetic-data-generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>steps</th>\n",
       "      <th>crabmeat</th>\n",
       "      <th>creamcheese</th>\n",
       "      <th>greenonions</th>\n",
       "      <th>garlicsalt</th>\n",
       "      <th>refrigeratedcrescentdinnerrolls</th>\n",
       "      <th>eggyolk</th>\n",
       "      <th>water</th>\n",
       "      <th>sesameseeds</th>\n",
       "      <th>...</th>\n",
       "      <th>tex-mexseasoning</th>\n",
       "      <th>lightnon-dairywhippedtopping</th>\n",
       "      <th>stelladoroanginetticookies</th>\n",
       "      <th>viennabread</th>\n",
       "      <th>beefroundrumproast</th>\n",
       "      <th>romaineleaf</th>\n",
       "      <th>nuocnam</th>\n",
       "      <th>thaiholybasil</th>\n",
       "      <th>driedblacktrumpetmushrooms</th>\n",
       "      <th>driedwoodearmushrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crab filled crescent snacks</td>\n",
       "      <td>heat over to 375 degrees, spray large cookie s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curried bean salad</td>\n",
       "      <td>drain &amp; rinse beans, stir all ingredients toge...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delicious steak with onion marinade</td>\n",
       "      <td>heat the oil in a heavy-based pan and cook the...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7686 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "0          crab filled crescent snacks   \n",
       "1                   curried bean salad   \n",
       "2  delicious steak with onion marinade   \n",
       "\n",
       "                                               steps  crabmeat  creamcheese  \\\n",
       "0  heat over to 375 degrees, spray large cookie s...       1.0          1.0   \n",
       "1  drain & rinse beans, stir all ingredients toge...       0.0          0.0   \n",
       "2  heat the oil in a heavy-based pan and cook the...       0.0          0.0   \n",
       "\n",
       "   greenonions  garlicsalt  refrigeratedcrescentdinnerrolls  eggyolk  water  \\\n",
       "0          1.0         1.0                              1.0      1.0    1.0   \n",
       "1          0.0         0.0                              0.0      0.0    0.0   \n",
       "2          0.0         0.0                              0.0      0.0    0.0   \n",
       "\n",
       "   sesameseeds  ...  tex-mexseasoning  lightnon-dairywhippedtopping  \\\n",
       "0          1.0  ...               0.0                           0.0   \n",
       "1          0.0  ...               0.0                           0.0   \n",
       "2          0.0  ...               0.0                           0.0   \n",
       "\n",
       "   stelladoroanginetticookies  viennabread  beefroundrumproast  romaineleaf  \\\n",
       "0                         0.0          0.0                 0.0          0.0   \n",
       "1                         0.0          0.0                 0.0          0.0   \n",
       "2                         0.0          0.0                 0.0          0.0   \n",
       "\n",
       "   nuocnam  thaiholybasil  driedblacktrumpetmushrooms  driedwoodearmushrooms  \n",
       "0      0.0            0.0                         0.0                    0.0  \n",
       "1      0.0            0.0                         0.0                    0.0  \n",
       "2      0.0            0.0                         0.0                    0.0  \n",
       "\n",
       "[3 rows x 7686 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# pd.options.display.max_columns = 500\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/kaggle/processed/recipes_processed.csv')#.sample(frac=0.1, random_state=42)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crabmeat</th>\n",
       "      <th>creamcheese</th>\n",
       "      <th>greenonions</th>\n",
       "      <th>garlicsalt</th>\n",
       "      <th>refrigeratedcrescentdinnerrolls</th>\n",
       "      <th>eggyolk</th>\n",
       "      <th>water</th>\n",
       "      <th>sesameseeds</th>\n",
       "      <th>sweetandsoursauce</th>\n",
       "      <th>garbanzobeans</th>\n",
       "      <th>...</th>\n",
       "      <th>tex-mexseasoning</th>\n",
       "      <th>lightnon-dairywhippedtopping</th>\n",
       "      <th>stelladoroanginetticookies</th>\n",
       "      <th>viennabread</th>\n",
       "      <th>beefroundrumproast</th>\n",
       "      <th>romaineleaf</th>\n",
       "      <th>nuocnam</th>\n",
       "      <th>thaiholybasil</th>\n",
       "      <th>driedblacktrumpetmushrooms</th>\n",
       "      <th>driedwoodearmushrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7684 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   crabmeat  creamcheese  greenonions  garlicsalt  \\\n",
       "0       1.0          1.0          1.0         1.0   \n",
       "1       0.0          0.0          0.0         0.0   \n",
       "2       0.0          0.0          0.0         0.0   \n",
       "3       0.0          0.0          0.0         0.0   \n",
       "4       0.0          0.0          0.0         0.0   \n",
       "\n",
       "   refrigeratedcrescentdinnerrolls  eggyolk  water  sesameseeds  \\\n",
       "0                              1.0      1.0    1.0          1.0   \n",
       "1                              0.0      0.0    0.0          0.0   \n",
       "2                              0.0      0.0    0.0          0.0   \n",
       "3                              0.0      0.0    0.0          0.0   \n",
       "4                              0.0      0.0    0.0          0.0   \n",
       "\n",
       "   sweetandsoursauce  garbanzobeans  ...  tex-mexseasoning  \\\n",
       "0                1.0            0.0  ...               0.0   \n",
       "1                0.0            1.0  ...               0.0   \n",
       "2                0.0            0.0  ...               0.0   \n",
       "3                0.0            0.0  ...               0.0   \n",
       "4                0.0            0.0  ...               0.0   \n",
       "\n",
       "   lightnon-dairywhippedtopping  stelladoroanginetticookies  viennabread  \\\n",
       "0                           0.0                         0.0          0.0   \n",
       "1                           0.0                         0.0          0.0   \n",
       "2                           0.0                         0.0          0.0   \n",
       "3                           0.0                         0.0          0.0   \n",
       "4                           0.0                         0.0          0.0   \n",
       "\n",
       "   beefroundrumproast  romaineleaf  nuocnam  thaiholybasil  \\\n",
       "0                 0.0          0.0      0.0            0.0   \n",
       "1                 0.0          0.0      0.0            0.0   \n",
       "2                 0.0          0.0      0.0            0.0   \n",
       "3                 0.0          0.0      0.0            0.0   \n",
       "4                 0.0          0.0      0.0            0.0   \n",
       "\n",
       "   driedblacktrumpetmushrooms  driedwoodearmushrooms  \n",
       "0                         0.0                    0.0  \n",
       "1                         0.0                    0.0  \n",
       "2                         0.0                    0.0  \n",
       "3                         0.0                    0.0  \n",
       "4                         0.0                    0.0  \n",
       "\n",
       "[5 rows x 7684 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['name', 'steps'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20268, 7684)\n",
      "(2896, 7684)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(df, test_size=0.125, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build functions and model definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 7684)              8624644   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 8525825   \n",
      "=================================================================\n",
      "Total params: 17,150,469\n",
      "Trainable params: 8,624,644\n",
      "Non-trainable params: 8,525,825\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Dropout, Input\n",
    "\n",
    "\n",
    "# Model configs\n",
    "noise_dim = 100\n",
    "dim = 256\n",
    "data_dim = df.shape[1]\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(dim, input_dim=noise_dim))\n",
    "    generator.add(Dense(dim, activation='relu'))\n",
    "    generator.add(Dense(dim * 2, activation='relu'))\n",
    "    generator.add(Dense(dim * 4, activation='relu'))\n",
    "    generator.add(Dense(data_dim, activation='tanh'))\n",
    "    \n",
    "    generator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    \n",
    "    discriminator.add(Dense(dim * 4, input_dim=data_dim))\n",
    "    discriminator.add(Dropout(0.1))\n",
    "    discriminator.add(Dense(dim * 2, activation='relu'))\n",
    "    discriminator.add(Dropout(0.1))\n",
    "    discriminator.add(Dense(dim, activation='relu'))\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return discriminator\n",
    "\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    # Only train generator in combined model\n",
    "    discriminator.trainable=False\n",
    "    \n",
    "    gan_input = Input(shape=(noise_dim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    \n",
    "    # Create the GAN model\n",
    "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "                      \n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return gan\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to display generator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_recipe(epoch, generator, examples=1):\n",
    "    # Create noise\n",
    "    noise = np.random.normal(0, 1, size=[examples, noise_dim])\n",
    "    \n",
    "    # Generate recipes\n",
    "    generated_recipes = generator.predict(noise)\n",
    "    \n",
    "    # Get used ingredients\n",
    "    ingredients = []\n",
    "    for i in range(generated_recipes.shape[0]):\n",
    "        for j in range(len(generated_recipes[i])):\n",
    "            if j >= 0.5:\n",
    "                ingredients.append(df.columns[j])\n",
    "    \n",
    "    # Display\n",
    "    print(\"*** Generated Recipe ***\")\n",
    "    print(f\"# of ingredients: {len(ingredients)}\")\n",
    "    print(f\"First 5 ingredients: {ingredients[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 [D Loss: 0.6740] [G loss: 5.2295]\n",
      "E2 [D Loss: 0.8111] [G loss: 2.1907]\n",
      "E3 [D Loss: 0.5032] [G loss: 4.1332]\n",
      "E4 [D Loss: 0.4007] [G loss: 4.6393]\n",
      "E5 [D Loss: 0.4575] [G loss: 2.4815]\n",
      "E6 [D Loss: 0.7069] [G loss: 1.2222]\n",
      "E7 [D Loss: 0.4367] [G loss: 4.3519]\n",
      "E8 [D Loss: 0.3534] [G loss: 5.4836]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E9 [D Loss: 0.4347] [G loss: 4.1558]\n",
      "E10 [D Loss: 0.4239] [G loss: 2.7290]\n",
      "E11 [D Loss: 0.3308] [G loss: 5.7464]\n",
      "E12 [D Loss: 0.3088] [G loss: 4.8660]\n",
      "E13 [D Loss: 0.3166] [G loss: 2.4262]\n",
      "E14 [D Loss: 0.2814] [G loss: 2.9938]\n",
      "E15 [D Loss: 0.2474] [G loss: 4.3313]\n",
      "E16 [D Loss: 0.1958] [G loss: 3.4016]\n",
      "E17 [D Loss: 0.1960] [G loss: 3.8628]\n",
      "E18 [D Loss: 0.2491] [G loss: 3.7912]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E19 [D Loss: 0.2992] [G loss: 2.9714]\n",
      "E20 [D Loss: 0.4005] [G loss: 2.5350]\n",
      "E21 [D Loss: 0.6557] [G loss: 2.0193]\n",
      "E22 [D Loss: 0.7293] [G loss: 2.2581]\n",
      "E23 [D Loss: 0.4832] [G loss: 2.7641]\n",
      "E24 [D Loss: 0.6177] [G loss: 2.4324]\n",
      "E25 [D Loss: 0.6976] [G loss: 2.1666]\n",
      "E26 [D Loss: 0.4696] [G loss: 2.6626]\n",
      "E27 [D Loss: 0.4020] [G loss: 3.1737]\n",
      "E28 [D Loss: 0.3491] [G loss: 5.1697]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E29 [D Loss: 0.2504] [G loss: 6.7123]\n",
      "E30 [D Loss: 0.1662] [G loss: 6.7513]\n",
      "E31 [D Loss: 0.3405] [G loss: 7.1850]\n",
      "E32 [D Loss: 0.0807] [G loss: 6.6241]\n",
      "E33 [D Loss: 0.0681] [G loss: 6.9876]\n",
      "E34 [D Loss: 0.2182] [G loss: 6.1227]\n",
      "E35 [D Loss: 0.2242] [G loss: 7.7358]\n",
      "E36 [D Loss: 1.5619] [G loss: 9.8714]\n",
      "E37 [D Loss: 0.1002] [G loss: 13.0959]\n",
      "E38 [D Loss: 1.0719] [G loss: 20.1533]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E39 [D Loss: 0.3189] [G loss: 33.6210]\n",
      "E40 [D Loss: 0.0496] [G loss: 40.4733]\n",
      "E41 [D Loss: 0.5875] [G loss: 43.2276]\n",
      "E42 [D Loss: 0.4624] [G loss: 39.9993]\n",
      "E43 [D Loss: 1.9857] [G loss: 51.1144]\n",
      "E44 [D Loss: 1.0913] [G loss: 66.9826]\n",
      "E45 [D Loss: 0.5270] [G loss: 65.1910]\n",
      "E46 [D Loss: 1.2857] [G loss: 51.9915]\n",
      "E47 [D Loss: 3.8361] [G loss: 79.4327]\n",
      "E48 [D Loss: 0.6389] [G loss: 97.1705]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E49 [D Loss: 0.9249] [G loss: 104.7177]\n",
      "E50 [D Loss: 0.9020] [G loss: 121.3443]\n",
      "E51 [D Loss: 0.5039] [G loss: 94.2207]\n",
      "E52 [D Loss: 0.7466] [G loss: 99.1605]\n",
      "E53 [D Loss: 0.1499] [G loss: 77.3603]\n",
      "E54 [D Loss: 0.9398] [G loss: 65.9685]\n",
      "E55 [D Loss: 0.5130] [G loss: 36.5932]\n",
      "E56 [D Loss: 0.3055] [G loss: 22.5870]\n",
      "E57 [D Loss: 1.2440] [G loss: 27.7811]\n",
      "E58 [D Loss: 1.2158] [G loss: 28.9490]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E59 [D Loss: 2.4115] [G loss: 31.9413]\n",
      "E60 [D Loss: 3.7471] [G loss: 18.2867]\n",
      "E61 [D Loss: 0.8138] [G loss: 15.0170]\n",
      "E62 [D Loss: 1.2514] [G loss: 24.8244]\n",
      "E63 [D Loss: 1.9467] [G loss: 24.0522]\n",
      "E64 [D Loss: 2.0491] [G loss: 32.5879]\n",
      "E65 [D Loss: 2.3005] [G loss: 29.1872]\n",
      "E66 [D Loss: 2.1904] [G loss: 29.6743]\n",
      "E67 [D Loss: 2.9699] [G loss: 27.1604]\n",
      "E68 [D Loss: 2.0421] [G loss: 28.7981]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E69 [D Loss: 2.4034] [G loss: 24.1561]\n",
      "E70 [D Loss: 1.5634] [G loss: 20.0418]\n",
      "E71 [D Loss: 1.2618] [G loss: 18.5786]\n",
      "E72 [D Loss: 0.7182] [G loss: 13.2606]\n",
      "E73 [D Loss: 1.3586] [G loss: 12.1061]\n",
      "E74 [D Loss: 0.4707] [G loss: 11.5082]\n",
      "E75 [D Loss: 0.3352] [G loss: 5.2704]\n",
      "E76 [D Loss: 0.5361] [G loss: 3.0258]\n",
      "E77 [D Loss: 0.4298] [G loss: 2.9090]\n",
      "E78 [D Loss: 0.8294] [G loss: 4.5947]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E79 [D Loss: 0.5006] [G loss: 3.3730]\n",
      "E80 [D Loss: 0.2708] [G loss: 3.7788]\n",
      "E81 [D Loss: 0.8188] [G loss: 1.1993]\n",
      "E82 [D Loss: 0.5055] [G loss: 4.8044]\n",
      "E83 [D Loss: 0.8613] [G loss: 4.4548]\n",
      "E84 [D Loss: 0.7823] [G loss: 7.1905]\n",
      "E85 [D Loss: 0.4422] [G loss: 4.5974]\n",
      "E86 [D Loss: 0.4772] [G loss: 8.1399]\n",
      "E87 [D Loss: 0.4679] [G loss: 8.7766]\n",
      "E88 [D Loss: 0.4902] [G loss: 9.6479]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E89 [D Loss: 0.9144] [G loss: 10.4378]\n",
      "E90 [D Loss: 0.7172] [G loss: 8.6098]\n",
      "E91 [D Loss: 0.6281] [G loss: 8.1542]\n",
      "E92 [D Loss: 0.3888] [G loss: 7.9009]\n",
      "E93 [D Loss: 0.5966] [G loss: 6.6537]\n",
      "E94 [D Loss: 0.4790] [G loss: 4.2725]\n",
      "E95 [D Loss: 0.4198] [G loss: 2.6945]\n",
      "E96 [D Loss: 0.4596] [G loss: 2.6103]\n",
      "E97 [D Loss: 0.3944] [G loss: 2.7478]\n",
      "E98 [D Loss: 0.4269] [G loss: 3.1736]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E99 [D Loss: 0.5652] [G loss: 2.6784]\n",
      "E100 [D Loss: 0.5506] [G loss: 3.4050]\n",
      "E101 [D Loss: 0.5790] [G loss: 3.5020]\n",
      "E102 [D Loss: 0.5531] [G loss: 2.7995]\n",
      "E103 [D Loss: 0.6448] [G loss: 2.5085]\n",
      "E104 [D Loss: 0.6887] [G loss: 1.5491]\n",
      "E105 [D Loss: 0.8677] [G loss: 2.3340]\n",
      "E106 [D Loss: 0.4599] [G loss: 3.6044]\n",
      "E107 [D Loss: 0.6115] [G loss: 3.2579]\n",
      "E108 [D Loss: 0.5889] [G loss: 3.0469]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E109 [D Loss: 0.6064] [G loss: 3.0075]\n",
      "E110 [D Loss: 0.7598] [G loss: 3.1817]\n",
      "E111 [D Loss: 0.6339] [G loss: 2.9472]\n",
      "E112 [D Loss: 0.7744] [G loss: 2.8484]\n",
      "E113 [D Loss: 0.8188] [G loss: 2.8629]\n",
      "E114 [D Loss: 0.7586] [G loss: 3.0196]\n",
      "E115 [D Loss: 0.8739] [G loss: 2.9031]\n",
      "E116 [D Loss: 0.7291] [G loss: 2.8883]\n",
      "E117 [D Loss: 0.6520] [G loss: 3.2075]\n",
      "E118 [D Loss: 0.5146] [G loss: 4.3581]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E119 [D Loss: 0.6476] [G loss: 6.0262]\n",
      "E120 [D Loss: 0.3630] [G loss: 6.8461]\n",
      "E121 [D Loss: 0.5511] [G loss: 7.2121]\n",
      "E122 [D Loss: 0.3902] [G loss: 6.5269]\n",
      "E123 [D Loss: 0.2846] [G loss: 5.2077]\n",
      "E124 [D Loss: 0.2853] [G loss: 3.2891]\n",
      "E125 [D Loss: 0.6753] [G loss: 1.2479]\n",
      "E126 [D Loss: 1.3517] [G loss: 0.3530]\n",
      "E127 [D Loss: 0.8873] [G loss: 0.8691]\n",
      "E128 [D Loss: 0.6673] [G loss: 3.7558]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E129 [D Loss: 0.7499] [G loss: 3.9348]\n",
      "E130 [D Loss: 0.4925] [G loss: 4.9161]\n",
      "E131 [D Loss: 0.4120] [G loss: 5.8773]\n",
      "E132 [D Loss: 0.3148] [G loss: 8.5389]\n",
      "E133 [D Loss: 0.4455] [G loss: 12.0098]\n",
      "E134 [D Loss: 0.4338] [G loss: 8.7493]\n",
      "E135 [D Loss: 0.4193] [G loss: 9.9781]\n",
      "E136 [D Loss: 0.5291] [G loss: 8.3668]\n",
      "E137 [D Loss: 0.5529] [G loss: 6.6416]\n",
      "E138 [D Loss: 0.3731] [G loss: 6.5231]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E139 [D Loss: 0.6359] [G loss: 3.9923]\n",
      "E140 [D Loss: 0.4333] [G loss: 3.6923]\n",
      "E141 [D Loss: 0.4520] [G loss: 3.0097]\n",
      "E142 [D Loss: 0.4557] [G loss: 2.8467]\n",
      "E143 [D Loss: 0.3692] [G loss: 2.3904]\n",
      "E144 [D Loss: 0.5041] [G loss: 1.7996]\n",
      "E145 [D Loss: 0.4484] [G loss: 1.2055]\n",
      "E146 [D Loss: 0.5527] [G loss: 1.2371]\n",
      "E147 [D Loss: 0.5472] [G loss: 1.1836]\n",
      "E148 [D Loss: 0.5714] [G loss: 1.2551]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E149 [D Loss: 0.5488] [G loss: 1.5691]\n",
      "E150 [D Loss: 0.4376] [G loss: 1.4589]\n",
      "E151 [D Loss: 0.4093] [G loss: 2.1765]\n",
      "E152 [D Loss: 0.4196] [G loss: 1.6581]\n",
      "E153 [D Loss: 0.4044] [G loss: 1.9521]\n",
      "E154 [D Loss: 0.4214] [G loss: 2.2293]\n",
      "E155 [D Loss: 0.4401] [G loss: 1.7748]\n",
      "E156 [D Loss: 0.4000] [G loss: 2.4506]\n",
      "E157 [D Loss: 0.4855] [G loss: 1.7209]\n",
      "E158 [D Loss: 0.5571] [G loss: 2.1135]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E159 [D Loss: 0.5233] [G loss: 2.3823]\n",
      "E160 [D Loss: 0.5324] [G loss: 1.9912]\n",
      "E161 [D Loss: 0.6631] [G loss: 0.8724]\n",
      "E162 [D Loss: 0.6774] [G loss: 1.6297]\n",
      "E163 [D Loss: 0.4820] [G loss: 1.1264]\n",
      "E164 [D Loss: 0.8158] [G loss: 1.9288]\n",
      "E165 [D Loss: 0.6634] [G loss: 1.3700]\n",
      "E166 [D Loss: 0.5184] [G loss: 1.1256]\n",
      "E167 [D Loss: 0.7051] [G loss: 2.2269]\n",
      "E168 [D Loss: 0.4622] [G loss: 2.0636]\n",
      "*** Generated Recipe ***\n",
      "# of ingredients: 7683\n",
      "First 5 ingredients: ['creamcheese', 'greenonions', 'garlicsalt', 'refrigeratedcrescentdinnerrolls', 'eggyolk']\n",
      "E169 [D Loss: 0.4903] [G loss: 3.0466]\n",
      "E170 [D Loss: 0.3524] [G loss: 2.4060]\n",
      "E171 [D Loss: 0.2988] [G loss: 3.4770]\n",
      "E172 [D Loss: 0.3265] [G loss: 3.6909]\n",
      "E173 [D Loss: 0.3483] [G loss: 3.4879]\n",
      "E174 [D Loss: 0.3453] [G loss: 3.3365]\n",
      "E175 [D Loss: 0.2959] [G loss: 2.8263]\n",
      "E176 [D Loss: 0.2930] [G loss: 2.2479]\n",
      "E177 [D Loss: 0.2953] [G loss: 2.3733]\n",
      "E178 [D Loss: 0.2602] [G loss: 2.3543]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7df8423b62fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-7df8423b62fa>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(X_train, X_test, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Display recipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mdisplay_recipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bf0f4709e643>\u001b[0m in \u001b[0;36mdisplay_recipe\u001b[0;34m(epoch, generator, examples)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Generate recipes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgenerated_recipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Get used ingredients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1241\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \"\"\"\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3975\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3976\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3977\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   3978\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3979\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[0;32m-> 2531\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   2532\u001b[0m         *args, **kwargs)\n\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3212\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3213\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3214\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3215\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3154\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3156\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3157\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Whitelisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def training(X_train, X_test, epochs=1, batch_size=32, sample_interval=10):\n",
    "    # Get batch count\n",
    "    batch_count = X_train.shape[0] / batch_size\n",
    "    \n",
    "    # Build GAN\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    gan = build_gan(generator, discriminator)\n",
    "    \n",
    "    # Training step\n",
    "    for e in range(1, epochs + 1):\n",
    "        # for _ in tqdm(range(batch_size)):\n",
    "            \n",
    "        # Random noise as an input to initialize the generator\n",
    "        noise = np.random.normal(0, 1, [batch_size, noise_dim])\n",
    "\n",
    "        # Use the GAN to generate \"fake\" recipes\n",
    "        generated_recipes = generator.predict(noise)\n",
    "\n",
    "        # Get a sample of real recipes from data\n",
    "        # real_recipes = X_train.loc[np.random.randint(low=0, high=X_train.shape[0], size=batch_size)]\n",
    "        real_recipes = X_train.sample(batch_size)\n",
    "\n",
    "        # Mix the real and fake data\n",
    "        X = np.concatenate([real_recipes, generated_recipes])\n",
    "\n",
    "        # Create labels for real and fake data\n",
    "        y_dis = np.zeros(2 * batch_size)  # fake\n",
    "        y_dis[:batch_size] = 1.0          # real\n",
    "\n",
    "        # Train the discriminator while generator is fixed\n",
    "        discriminator.trainable = True\n",
    "        d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "        # Fix the images generated by the generator as real \n",
    "        noise = np.random.normal(0, 1, [batch_size, noise_dim])\n",
    "        y_gen = np.ones(batch_size)\n",
    "\n",
    "        # Train the generator (to have the discriminator label samples as valid)\n",
    "        discriminator.trainable = False\n",
    "        g_loss = gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "        # Output loss\n",
    "        print(f\"E{e} [D Loss: {d_loss:.4f}] [G loss: {g_loss:.4f}]\")\n",
    "            \n",
    "        # Display created recipes at a given epoch interval\n",
    "        if e % sample_interval == 8:\n",
    "            # Display recipe\n",
    "            display_recipe(e, generator)\n",
    "    \n",
    "    return generator, discriminator, gan\n",
    "\n",
    "\n",
    "generator, discriminator, gan = training(X_train, X_test, epochs=256, batch_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
