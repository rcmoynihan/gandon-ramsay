{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIS 285N Cognitive Computing<br>\n",
    "Final Project<br>\n",
    "Jerry Che - Jose Guerrero - Riley Moynihan - Noah Placke - Sarah Teng - Palmer Wenzel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredients Generation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following techniques from:\n",
    "- https://towardsdatascience.com/generative-adversarial-networks-in-python-73d3972823d3\n",
    "- https://www.maskaravivek.com/post/gan-synthetic-data-generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.options.display.max_columns = 500\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/kaggle/processed/recipes_processed_sml.csv')#.sample(frac=0.1, random_state=42)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['name', 'steps'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(df, test_size=0.125, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build functions and model definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Dropout, Input\n",
    "\n",
    "\n",
    "# Model configs\n",
    "noise_dim = 100\n",
    "dim = 256\n",
    "data_dim = df.shape[1]\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(dim, input_dim=noise_dim))\n",
    "    generator.add(Dense(dim, activation='relu'))\n",
    "    generator.add(Dense(dim * 2, activation='relu'))\n",
    "    generator.add(Dense(dim * 4, activation='relu'))\n",
    "    generator.add(Dense(data_dim, activation='tanh'))\n",
    "    \n",
    "    generator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    \n",
    "    discriminator.add(Dense(dim * 4, input_dim=data_dim))\n",
    "    discriminator.add(Dropout(0.1))\n",
    "    discriminator.add(Dense(dim * 2, activation='relu'))\n",
    "    discriminator.add(Dropout(0.1))\n",
    "    discriminator.add(Dense(dim, activation='relu'))\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return discriminator\n",
    "\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    # Only train generator in combined model\n",
    "    discriminator.trainable=False\n",
    "    \n",
    "    gan_input = Input(shape=(noise_dim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    \n",
    "    # Create the GAN model\n",
    "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "                      \n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return gan\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to display generator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_recipe(epoch, generator, examples=1):\n",
    "    # Create noise\n",
    "    noise = np.random.normal(0, 1, size=[examples, noise_dim])\n",
    "    \n",
    "    # Generate recipes\n",
    "    generated_recipes = generator.predict(noise)\n",
    "    \n",
    "    # Get used ingredients\n",
    "    ingredients = []\n",
    "    for i in range(generated_recipes.shape[0]):\n",
    "        for j in range(len(generated_recipes[i])):\n",
    "            if j >= 0.5:\n",
    "                ingredients.append(df.columns[j])\n",
    "    \n",
    "    # Display\n",
    "    print(\"*** Generated Recipe ***\")\n",
    "    print(f\"# of ingredients: {len(ingredients)}\")\n",
    "    print(f\"First 5 ingredients: {ingredients[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def training(X_train, X_test, epochs=1, batch_size=32, sample_interval=10):\n",
    "    # Get batch count\n",
    "    batch_count = X_train.shape[0] / batch_size\n",
    "    \n",
    "    # Build GAN\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    gan = build_gan(generator, discriminator)\n",
    "    \n",
    "    # Training step\n",
    "    for e in range(1, epochs + 1):\n",
    "        # for _ in tqdm(range(batch_size)):\n",
    "            \n",
    "        # Random noise as an input to initialize the generator\n",
    "        noise = np.random.normal(0, 1, [batch_size, noise_dim])\n",
    "\n",
    "        # Use the GAN to generate \"fake\" recipes\n",
    "        generated_recipes = generator.predict(noise)\n",
    "\n",
    "        # Get a sample of real recipes from data\n",
    "        # real_recipes = X_train.loc[np.random.randint(low=0, high=X_train.shape[0], size=batch_size)]\n",
    "        real_recipes = X_train.sample(batch_size)\n",
    "\n",
    "        # Mix the real and fake data\n",
    "        X = np.concatenate([real_recipes, generated_recipes])\n",
    "\n",
    "        # Create labels for real and fake data\n",
    "        y_dis = np.zeros(2 * batch_size)  # fake\n",
    "        y_dis[:batch_size] = 1.0          # real\n",
    "\n",
    "        # Train the discriminator while generator is fixed\n",
    "        discriminator.trainable = True\n",
    "        d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "        # Fix the images generated by the generator as real \n",
    "        noise = np.random.normal(0, 1, [batch_size, noise_dim])\n",
    "        y_gen = np.ones(batch_size)\n",
    "\n",
    "        # Train the generator (to have the discriminator label samples as valid)\n",
    "        discriminator.trainable = False\n",
    "        g_loss = gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "        # Output loss\n",
    "        print(f\"E{e} [D Loss: {d_loss:.4f}] [G loss: {g_loss:.4f}]\")\n",
    "            \n",
    "        # Display created recipes at a given epoch interval\n",
    "        if e % sample_interval == 8:\n",
    "            # Display recipe\n",
    "            display_recipe(e, generator)\n",
    "    \n",
    "    return generator, discriminator, gan\n",
    "\n",
    "\n",
    "generator, discriminator, gan = training(X_train, X_test, epochs=256, batch_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
