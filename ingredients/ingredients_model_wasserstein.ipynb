{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIS 285N Cognitive Computing<br>\n",
    "Final Project<br>\n",
    "Jerry Che - Jose Guerrero - Riley Moynihan - Noah Placke - Sarah Teng - Palmer Wenzel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredients Generation Model (Wasserstein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following techniques from:\n",
    "- https://towardsdatascience.com/generative-adversarial-networks-in-python-73d3972823d3\n",
    "- https://www.maskaravivek.com/post/gan-synthetic-data-generation/\n",
    "- (for Wasserstein modifications) https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>steps</th>\n",
       "      <th>crabmeat</th>\n",
       "      <th>creamcheese</th>\n",
       "      <th>greenonions</th>\n",
       "      <th>garlicsalt</th>\n",
       "      <th>refrigeratedcrescentdinnerrolls</th>\n",
       "      <th>eggyolk</th>\n",
       "      <th>water</th>\n",
       "      <th>sesameseeds</th>\n",
       "      <th>...</th>\n",
       "      <th>tex-mexseasoning</th>\n",
       "      <th>lightnon-dairywhippedtopping</th>\n",
       "      <th>stelladoroanginetticookies</th>\n",
       "      <th>viennabread</th>\n",
       "      <th>beefroundrumproast</th>\n",
       "      <th>romaineleaf</th>\n",
       "      <th>nuocnam</th>\n",
       "      <th>thaiholybasil</th>\n",
       "      <th>driedblacktrumpetmushrooms</th>\n",
       "      <th>driedwoodearmushrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crab filled crescent snacks</td>\n",
       "      <td>heat over to 375 degrees, spray large cookie s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curried bean salad</td>\n",
       "      <td>drain &amp; rinse beans, stir all ingredients toge...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delicious steak with onion marinade</td>\n",
       "      <td>heat the oil in a heavy-based pan and cook the...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 7686 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "0          crab filled crescent snacks   \n",
       "1                   curried bean salad   \n",
       "2  delicious steak with onion marinade   \n",
       "\n",
       "                                               steps  crabmeat  creamcheese  \\\n",
       "0  heat over to 375 degrees, spray large cookie s...       1.0          1.0   \n",
       "1  drain & rinse beans, stir all ingredients toge...       0.0          0.0   \n",
       "2  heat the oil in a heavy-based pan and cook the...       0.0          0.0   \n",
       "\n",
       "   greenonions  garlicsalt  refrigeratedcrescentdinnerrolls  eggyolk  water  \\\n",
       "0          1.0         1.0                              1.0      1.0    1.0   \n",
       "1          0.0         0.0                              0.0      0.0    0.0   \n",
       "2          0.0         0.0                              0.0      0.0    0.0   \n",
       "\n",
       "   sesameseeds  ...  tex-mexseasoning  lightnon-dairywhippedtopping  \\\n",
       "0          1.0  ...               0.0                           0.0   \n",
       "1          0.0  ...               0.0                           0.0   \n",
       "2          0.0  ...               0.0                           0.0   \n",
       "\n",
       "   stelladoroanginetticookies  viennabread  beefroundrumproast  romaineleaf  \\\n",
       "0                         0.0          0.0                 0.0          0.0   \n",
       "1                         0.0          0.0                 0.0          0.0   \n",
       "2                         0.0          0.0                 0.0          0.0   \n",
       "\n",
       "   nuocnam  thaiholybasil  driedblacktrumpetmushrooms  driedwoodearmushrooms  \n",
       "0      0.0            0.0                         0.0                    0.0  \n",
       "1      0.0            0.0                         0.0                    0.0  \n",
       "2      0.0            0.0                         0.0                    0.0  \n",
       "\n",
       "[3 rows x 7686 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# pd.options.display.max_columns = 500\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/kaggle/processed/recipes_processed.csv')#.sample(frac=0.1, random_state=42)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crabmeat</th>\n",
       "      <th>creamcheese</th>\n",
       "      <th>greenonions</th>\n",
       "      <th>garlicsalt</th>\n",
       "      <th>refrigeratedcrescentdinnerrolls</th>\n",
       "      <th>eggyolk</th>\n",
       "      <th>water</th>\n",
       "      <th>sesameseeds</th>\n",
       "      <th>sweetandsoursauce</th>\n",
       "      <th>garbanzobeans</th>\n",
       "      <th>...</th>\n",
       "      <th>tex-mexseasoning</th>\n",
       "      <th>lightnon-dairywhippedtopping</th>\n",
       "      <th>stelladoroanginetticookies</th>\n",
       "      <th>viennabread</th>\n",
       "      <th>beefroundrumproast</th>\n",
       "      <th>romaineleaf</th>\n",
       "      <th>nuocnam</th>\n",
       "      <th>thaiholybasil</th>\n",
       "      <th>driedblacktrumpetmushrooms</th>\n",
       "      <th>driedwoodearmushrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7684 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   crabmeat  creamcheese  greenonions  garlicsalt  \\\n",
       "0       1.0          1.0          1.0         1.0   \n",
       "1       0.0          0.0          0.0         0.0   \n",
       "2       0.0          0.0          0.0         0.0   \n",
       "3       0.0          0.0          0.0         0.0   \n",
       "4       0.0          0.0          0.0         0.0   \n",
       "\n",
       "   refrigeratedcrescentdinnerrolls  eggyolk  water  sesameseeds  \\\n",
       "0                              1.0      1.0    1.0          1.0   \n",
       "1                              0.0      0.0    0.0          0.0   \n",
       "2                              0.0      0.0    0.0          0.0   \n",
       "3                              0.0      0.0    0.0          0.0   \n",
       "4                              0.0      0.0    0.0          0.0   \n",
       "\n",
       "   sweetandsoursauce  garbanzobeans  ...  tex-mexseasoning  \\\n",
       "0                1.0            0.0  ...               0.0   \n",
       "1                0.0            1.0  ...               0.0   \n",
       "2                0.0            0.0  ...               0.0   \n",
       "3                0.0            0.0  ...               0.0   \n",
       "4                0.0            0.0  ...               0.0   \n",
       "\n",
       "   lightnon-dairywhippedtopping  stelladoroanginetticookies  viennabread  \\\n",
       "0                           0.0                         0.0          0.0   \n",
       "1                           0.0                         0.0          0.0   \n",
       "2                           0.0                         0.0          0.0   \n",
       "3                           0.0                         0.0          0.0   \n",
       "4                           0.0                         0.0          0.0   \n",
       "\n",
       "   beefroundrumproast  romaineleaf  nuocnam  thaiholybasil  \\\n",
       "0                 0.0          0.0      0.0            0.0   \n",
       "1                 0.0          0.0      0.0            0.0   \n",
       "2                 0.0          0.0      0.0            0.0   \n",
       "3                 0.0          0.0      0.0            0.0   \n",
       "4                 0.0          0.0      0.0            0.0   \n",
       "\n",
       "   driedblacktrumpetmushrooms  driedwoodearmushrooms  \n",
       "0                         0.0                    0.0  \n",
       "1                         0.0                    0.0  \n",
       "2                         0.0                    0.0  \n",
       "3                         0.0                    0.0  \n",
       "4                         0.0                    0.0  \n",
       "\n",
       "[5 rows x 7684 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['name', 'steps'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20268, 7684)\n",
      "(2896, 7684)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(df, test_size=0.125, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build functions and model definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom loss for Wasserstein implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight clipping for Wasserstein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import Constraint\n",
    "\n",
    "\n",
    "# Clip model weights to a given hypercube\n",
    "class ClipConstraint(Constraint):\n",
    "\t# set clip value when initialized\n",
    "\tdef __init__(self, clip_value):\n",
    "\t\tself.clip_value = clip_value\n",
    "\n",
    "\t# clip model weights to hypercube\n",
    "\tdef __call__(self, weights):\n",
    "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
    "\n",
    "\t# get the config\n",
    "\tdef get_config(self):\n",
    "\t\treturn {'clip_value': self.clip_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 7684)              4135940   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 4099073   \n",
      "=================================================================\n",
      "Total params: 8,235,013\n",
      "Trainable params: 4,135,940\n",
      "Non-trainable params: 4,099,073\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Dropout, Input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "# Model configs\n",
    "noise_dim = 100\n",
    "dim = 128\n",
    "data_dim = df.shape[1]\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(dim, input_dim=noise_dim))\n",
    "    generator.add(Dense(dim, activation='relu'))\n",
    "    generator.add(Dense(dim * 2, activation='relu'))\n",
    "    generator.add(Dense(dim * 4, activation='relu'))\n",
    "    generator.add(Dense(data_dim, activation='tanh'))\n",
    "    \n",
    "    generator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    \n",
    "    discriminator.add(Dense(dim * 4, input_dim=data_dim))\n",
    "    discriminator.add(Dropout(0.1))\n",
    "    discriminator.add(Dense(dim * 2, activation='relu', kernel_constraint=ClipConstraint(0.01)))\n",
    "    discriminator.add(Dropout(0.1))\n",
    "    discriminator.add(Dense(dim, activation='relu', kernel_constraint=ClipConstraint(0.01)))  # weight clip constraint for Wasserstein\n",
    "    discriminator.add(Dense(1, activation='linear'))  # was sigmoid for normal DCGAN, linear for Wasserstein\n",
    "    \n",
    "    discriminator.compile(loss=wasserstein_loss, optimizer='adam')  # loss was binary_crossentropy, now custom for Wasserstein\n",
    "    \n",
    "    return discriminator\n",
    "\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    # Only train generator in combined model\n",
    "    discriminator.trainable=False\n",
    "    \n",
    "    gan = Sequential()\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "    \n",
    "    # Use RMSProp for optimizer for Wasserstein\n",
    "    opt = RMSprop(lr=0.00005)\n",
    "                      \n",
    "    gan.compile(loss='binary_crossentropy', optimizer=opt)  # was Adam for DCGAN, now RMSProp for Wasserstein\n",
    "    \n",
    "    return gan\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create function to display generator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_recipe(epoch, generator, examples=1):\n",
    "    # Create noise\n",
    "    # noise = np.random.normal(0, 1, size=[examples, noise_dim])\n",
    "    # noise = np.random.laplace(0, 1, size=[examples, noise_dim])\n",
    "    noise = random_noise(examples)\n",
    "    \n",
    "    # Generate recipes\n",
    "    generated_recipes = generator.predict(noise)\n",
    "    \n",
    "#     # Get used ingredients\n",
    "#     ingredients = []\n",
    "#     for i in range(generated_recipes.shape[0]):\n",
    "#         for j in range(len(generated_recipes[i])):\n",
    "#             if generated_recipes[i][j] >= 0.25:\n",
    "                \n",
    "#                 ingredients.append(df.columns[j])\n",
    "    \n",
    "#     # Display\n",
    "#     print(\"*** Generated Recipe ***\")\n",
    "#     print(f\"# of ingredients: {len(ingredients)}\")\n",
    "#     print(f\"Ingredients: {ingredients[:]}\")\n",
    "#     print(generated_recipes[i])\n",
    "\n",
    "    # Use top N ingredients for recipe\n",
    "    ingredients = []\n",
    "    top_ingredients_idx = generated_recipes[0].argsort()[-10:][::-1]\n",
    "    for idx in top_ingredients_idx:\n",
    "        ingredients.append(df.columns[idx])\n",
    "        \n",
    "    # Display\n",
    "    print(\"*** GENERATED RECIPE ***\")\n",
    "    print(f\"Ingredients: {ingredients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def random_noise(num):\n",
    "    # return np.random.normal(0, 1, size=[num, noise_dim])\n",
    "    # return np.random.laplace(0, 1, size=[num, noise_dim])\n",
    "    noise = np.random.laplace(0, 1, size=[num, noise_dim])\n",
    "    for i in range(len(noise)):\n",
    "        for j in range(len(noise[i])):\n",
    "            if random.random() < 0.9:\n",
    "                noise[i][j] = 0.0\n",
    "    \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 [D Loss: -1.8370] [G loss: -15.4249]\n",
      "E2 [D Loss: -25.7940] [G loss: -15.4249]\n",
      "E3 [D Loss: -86.3549] [G loss: -15.4249]\n",
      "E4 [D Loss: -139.5101] [G loss: -15.4249]\n",
      "E5 [D Loss: -199.2348] [G loss: -15.4249]\n",
      "E6 [D Loss: -285.1061] [G loss: -15.4249]\n",
      "E7 [D Loss: -317.0115] [G loss: -15.4249]\n",
      "E8 [D Loss: -474.1365] [G loss: -15.4249]\n",
      "E9 [D Loss: -515.4952] [G loss: -15.4249]\n",
      "E10 [D Loss: -621.2281] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['pricklypearjuice', 'chickenleg', 'groundmustard', 'wholewheatcereal', 'cheddarcheesesoup', 'low-fatchocolatefrozenyogurt', 'blacksalt', 'oil-curedblackolives', 'spongecakes', 'drypennepasta']\n",
      "E11 [D Loss: -843.6407] [G loss: -15.4249]\n",
      "E12 [D Loss: -1090.3103] [G loss: -15.4249]\n",
      "E13 [D Loss: -1148.2402] [G loss: -15.4249]\n",
      "E14 [D Loss: -1331.5249] [G loss: -15.4249]\n",
      "E15 [D Loss: -1508.4752] [G loss: -15.4249]\n",
      "E16 [D Loss: -1735.0857] [G loss: -15.4249]\n",
      "E17 [D Loss: -2205.0386] [G loss: -15.4249]\n",
      "E18 [D Loss: -1897.4189] [G loss: -15.4249]\n",
      "E19 [D Loss: -2404.8154] [G loss: -15.4249]\n",
      "E20 [D Loss: -2357.0527] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['jumboblackolives', 'oil-curedblackolives', 'whiteonions', 'chocolatecurls', 'spongecakes', 'yellowsweetonions', 'low-fatwhippingcream', 'greengiantwhiteandwildricewithfrenchstylegreenbeans', 'chickenbreast', 'solidpackpumpkin']\n",
      "E21 [D Loss: -2858.3555] [G loss: -15.4249]\n",
      "E22 [D Loss: -2838.6389] [G loss: -15.4249]\n",
      "E23 [D Loss: -3508.2473] [G loss: -15.4249]\n",
      "E24 [D Loss: -3778.9175] [G loss: -15.4249]\n",
      "E25 [D Loss: -3513.5137] [G loss: -15.4249]\n",
      "E26 [D Loss: -4297.7031] [G loss: -15.4249]\n",
      "E27 [D Loss: -5602.7070] [G loss: -15.4249]\n",
      "E28 [D Loss: -4878.9512] [G loss: -15.4249]\n",
      "E29 [D Loss: -4732.7178] [G loss: -15.4249]\n",
      "E30 [D Loss: -6566.4224] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['oil-curedblackolives', 'mildcheddarcheese', 'nachocheeseflavoredtortillachips', 'turkeystuffing', 'solidpackpumpkin', 'fatfreesugar-freeinstantchocolatefudgepuddingmix', 'groundmustard', 'jumboblackolives', 'mushroomstockcubes', 'macaroninoodles']\n",
      "E31 [D Loss: -5849.8452] [G loss: -15.4249]\n",
      "E32 [D Loss: -6418.9175] [G loss: -15.4249]\n",
      "E33 [D Loss: -6858.2544] [G loss: -15.4249]\n",
      "E34 [D Loss: -6651.1860] [G loss: -15.4249]\n",
      "E35 [D Loss: -6709.2070] [G loss: -15.4249]\n",
      "E36 [D Loss: -10329.5410] [G loss: -15.4249]\n",
      "E37 [D Loss: -8877.4404] [G loss: -15.4249]\n",
      "E38 [D Loss: -8678.4326] [G loss: -15.4249]\n",
      "E39 [D Loss: -11545.1035] [G loss: -15.4249]\n",
      "E40 [D Loss: -9636.9424] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['mirasolchiles', 'dirtyricemix', 'balsamicvinaigrette', 'texastoastthickbread', 'lemonslices', 'rollocandies', 'caperjuice', 'vanillachocolatechips', 'whitechocolatebakingsquares', 'thairedchilipeppers']\n",
      "E41 [D Loss: -9899.2881] [G loss: -15.4249]\n",
      "E42 [D Loss: -10228.6396] [G loss: -15.4249]\n",
      "E43 [D Loss: -11663.4141] [G loss: -15.4249]\n",
      "E44 [D Loss: -12026.5332] [G loss: -15.4249]\n",
      "E45 [D Loss: -12995.3779] [G loss: -15.4249]\n",
      "E46 [D Loss: -15871.1484] [G loss: -15.4249]\n",
      "E47 [D Loss: -12053.1719] [G loss: -15.4249]\n",
      "E48 [D Loss: -16484.9766] [G loss: -15.4249]\n",
      "E49 [D Loss: -18082.7832] [G loss: -15.4249]\n",
      "E50 [D Loss: -18148.2070] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['milo', 'toothpick', 'oil-curedblackolives', 'groundmustard', 'boule', 'almondfilling', 'pineappletidbits', 'tortillas', 'whiteonions', 'ricecakes']\n",
      "E51 [D Loss: -16160.3223] [G loss: -15.4249]\n",
      "E52 [D Loss: -18548.2090] [G loss: -15.4249]\n",
      "E53 [D Loss: -18066.3750] [G loss: -15.4249]\n",
      "E54 [D Loss: -16556.7930] [G loss: -15.4249]\n",
      "E55 [D Loss: -20968.7539] [G loss: -15.4249]\n",
      "E56 [D Loss: -19784.9160] [G loss: -15.4249]\n",
      "E57 [D Loss: -18212.7285] [G loss: -15.4249]\n",
      "E58 [D Loss: -19208.3633] [G loss: -15.4249]\n",
      "E59 [D Loss: -21039.5254] [G loss: -15.4249]\n",
      "E60 [D Loss: -22438.8594] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['cashews', 'coarseseasalt', 'jumboblackolives', 'crackercrumbs', 'smallelbowmacaroni', 'soymilk', 'oil-curedblackolives', 'driedblacktrumpetmushrooms', 'low-fatwhippingcream', 'coffeefilter']\n",
      "E61 [D Loss: -26398.2930] [G loss: -15.4249]\n",
      "E62 [D Loss: -21081.6484] [G loss: -15.4249]\n",
      "E63 [D Loss: -22137.4648] [G loss: -15.4249]\n",
      "E64 [D Loss: -22207.2852] [G loss: -15.4249]\n",
      "E65 [D Loss: -23103.3672] [G loss: -15.4249]\n",
      "E66 [D Loss: -30312.1816] [G loss: -15.4249]\n",
      "E67 [D Loss: -27213.8984] [G loss: -15.4249]\n",
      "E68 [D Loss: -25527.9180] [G loss: -15.4249]\n",
      "E69 [D Loss: -29845.3633] [G loss: -15.4249]\n",
      "E70 [D Loss: -34312.1641] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['hotchickenstock', 'yellowsweetonions', 'gemlettuce', 'risottorice', '\"bakerssemi-sweetchocolate\"', 'artificialsweetener', 'fatfreespaghettisauce', 'crackedice', 'chickenbreast', 'whiteonions']\n",
      "E71 [D Loss: -30813.6660] [G loss: -15.4249]\n",
      "E72 [D Loss: -34900.7148] [G loss: -15.4249]\n",
      "E73 [D Loss: -29170.5469] [G loss: -15.4249]\n",
      "E74 [D Loss: -34305.7891] [G loss: -15.4249]\n",
      "E75 [D Loss: -33533.1875] [G loss: -15.4249]\n",
      "E76 [D Loss: -32953.2109] [G loss: -15.4249]\n",
      "E77 [D Loss: -35151.4883] [G loss: -15.4249]\n",
      "E78 [D Loss: -36543.1289] [G loss: -15.4249]\n",
      "E79 [D Loss: -42931.5898] [G loss: -15.4249]\n",
      "E80 [D Loss: -36324.8477] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['nachocheeseflavoredtortillachips', 'papayanectar', 'oil-curedblackolives', 'mushroomstockcubes', 'whitepearlonion', 'leangroundveal', 'frozenbeefburgerpatties', 'montereyjackcheese', 'reduced-fatvanillaicecream', 'fatfreeranchdressing']\n",
      "E81 [D Loss: -36282.0000] [G loss: -15.4249]\n",
      "E82 [D Loss: -40023.6172] [G loss: -15.4249]\n",
      "E83 [D Loss: -42702.4844] [G loss: -15.4249]\n",
      "E84 [D Loss: -42821.7852] [G loss: -15.4249]\n",
      "E85 [D Loss: -49153.7422] [G loss: -15.4249]\n",
      "E86 [D Loss: -43646.8516] [G loss: -15.4249]\n",
      "E87 [D Loss: -40106.9062] [G loss: -15.4249]\n",
      "E88 [D Loss: -57777.9141] [G loss: -15.4249]\n",
      "E89 [D Loss: -47520.7266] [G loss: -15.4249]\n",
      "E90 [D Loss: -47318.5430] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['orangedrinkmix', 'cheddarcheesesoup', 'caperjuice', 'chickenleg', 'sageleaves', 'pricklypearjuice', 'rawspinachleaves', '\"confectionerssugar\"', 'babyclams', 'low-sodiumchickpeas']\n",
      "E91 [D Loss: -40491.0234] [G loss: -15.4249]\n",
      "E92 [D Loss: -55179.9531] [G loss: -15.4249]\n",
      "E93 [D Loss: -49080.6289] [G loss: -15.4249]\n",
      "E94 [D Loss: -59120.4219] [G loss: -15.4249]\n",
      "E95 [D Loss: -52353.8672] [G loss: -15.4249]\n",
      "E96 [D Loss: -59348.2734] [G loss: -15.4249]\n",
      "E97 [D Loss: -56493.3750] [G loss: -15.4249]\n",
      "E98 [D Loss: -58750.5078] [G loss: -15.4249]\n",
      "E99 [D Loss: -56656.0977] [G loss: -15.4249]\n",
      "E100 [D Loss: -54688.1328] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['turkeystuffing', 'oil-curedblackolives', 'crackedice', 'shoyu', 'cheddarcheesesoup', 'nachocheeseflavoredtortillachips', 'semi-sweetchocolatebakingsquares', 'boule', 'driedblacktrumpetmushrooms', 'consomme']\n",
      "E101 [D Loss: -67786.6406] [G loss: -15.4249]\n",
      "E102 [D Loss: -63746.1328] [G loss: -15.4249]\n",
      "E103 [D Loss: -69119.8750] [G loss: -15.4249]\n",
      "E104 [D Loss: -69301.7109] [G loss: -15.4249]\n",
      "E105 [D Loss: -66781.9219] [G loss: -15.4249]\n",
      "E106 [D Loss: -71397.7812] [G loss: -15.4249]\n",
      "E107 [D Loss: -70306.6484] [G loss: -15.4249]\n",
      "E108 [D Loss: -70158.5156] [G loss: -15.4249]\n",
      "E109 [D Loss: -68193.1797] [G loss: -15.4249]\n",
      "E110 [D Loss: -60843.1172] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['chickenleg', 'texastoastthickbread', 'leangroundveal', 'cheddarcheesesoup', 'drylasagnanoodle', 'nachocheeseflavoredtortillachips', 'frenchharicotsvert', 'yolk-freewideeggnoodles', 'shoyu', 'breadedchickennuggets']\n",
      "E111 [D Loss: -77957.9062] [G loss: -15.4249]\n",
      "E112 [D Loss: -78252.3203] [G loss: -15.4249]\n",
      "E113 [D Loss: -75689.3906] [G loss: -15.4249]\n",
      "E114 [D Loss: -87850.5000] [G loss: -15.4249]\n",
      "E115 [D Loss: -68786.6328] [G loss: -15.4249]\n",
      "E116 [D Loss: -91025.3359] [G loss: -15.4249]\n",
      "E117 [D Loss: -69941.3125] [G loss: -15.4249]\n",
      "E118 [D Loss: -77087.1719] [G loss: -15.4249]\n",
      "E119 [D Loss: -84638.6250] [G loss: -15.4249]\n",
      "E120 [D Loss: -90532.0781] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['crackercrumb', 'scallopedpotatoesmix', 'solidpackpumpkin', 'fatfreespaghettisauce', 'oil-curedblackolives', 'driedfineherbs', 'corntortillastrips', 'whiteonions', 'haddockfillets', 'drypasta']\n",
      "E121 [D Loss: -83854.2188] [G loss: -15.4249]\n",
      "E122 [D Loss: -93043.7031] [G loss: -15.4249]\n",
      "E123 [D Loss: -99694.7031] [G loss: -15.4249]\n",
      "E124 [D Loss: -107392.0703] [G loss: -15.4249]\n",
      "E125 [D Loss: -87560.1875] [G loss: -15.4249]\n",
      "E126 [D Loss: -99156.0781] [G loss: -15.4249]\n",
      "E127 [D Loss: -83675.0625] [G loss: -15.4249]\n",
      "E128 [D Loss: -96187.1875] [G loss: -15.4249]\n",
      "E129 [D Loss: -103360.9453] [G loss: -15.4249]\n",
      "E130 [D Loss: -122610.3672] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['rawspinachleaves', 'oil-curedblackolives', 'fatfreespaghettisauce', 'greengiantwhiteandwildricewithfrenchstylegreenbeans', 'frankfurters', 'bostonlettuceleaves', 'whiteonions', 'yellowsweetonions', 'spanishricemix', 'rawwildrice']\n",
      "E131 [D Loss: -115223.7578] [G loss: -15.4249]\n",
      "E132 [D Loss: -100765.2109] [G loss: -15.4249]\n",
      "E133 [D Loss: -96228.8281] [G loss: -15.4249]\n",
      "E134 [D Loss: -103646.4531] [G loss: -15.4249]\n",
      "E135 [D Loss: -112536.5469] [G loss: -15.4249]\n",
      "E136 [D Loss: -107397.7188] [G loss: -15.4249]\n",
      "E137 [D Loss: -123641.5078] [G loss: -15.4249]\n",
      "E138 [D Loss: -92798.1328] [G loss: -15.4249]\n",
      "E139 [D Loss: -113177.3750] [G loss: -15.4249]\n",
      "E140 [D Loss: -105751.6719] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['dirtyricemix', 'chocolategrahamcrackers', 'cannedmushroom', 'montrachet', 'leanhamburger', 'fatfreespaghettisauce', 'low-sodiumchickpeas', 'cookedvermicelli', 'cranberryvodka', 'tictacmint']\n",
      "E141 [D Loss: -114154.1094] [G loss: -15.4249]\n",
      "E142 [D Loss: -123820.4375] [G loss: -15.4249]\n",
      "E143 [D Loss: -138244.8125] [G loss: -15.4249]\n",
      "E144 [D Loss: -120670.1406] [G loss: -15.4249]\n",
      "E145 [D Loss: -125266.8516] [G loss: -15.4249]\n",
      "E146 [D Loss: -134377.3125] [G loss: -15.4249]\n",
      "E147 [D Loss: -139679.7969] [G loss: -15.4249]\n",
      "E148 [D Loss: -130799.5234] [G loss: -15.4249]\n",
      "E149 [D Loss: -142098.4219] [G loss: -15.4249]\n",
      "E150 [D Loss: -147909.7344] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['darkchocolatebars', 'oil-curedblackolives', 'semi-sweetchocolatebakingsquares', 'bicarbonateofsoda', 'greengrapes', 'porkribs', 'rawwildrice', 'rawcranberries', 'blacktreacle', 'vanillainstantpuddingmix']\n",
      "E151 [D Loss: -151185.3125] [G loss: -15.4249]\n",
      "E152 [D Loss: -146235.4375] [G loss: -15.4249]\n",
      "E153 [D Loss: -132462.2812] [G loss: -15.4249]\n",
      "E154 [D Loss: -152453.8438] [G loss: -15.4249]\n",
      "E155 [D Loss: -128744.1797] [G loss: -15.4249]\n",
      "E156 [D Loss: -139926.9062] [G loss: -15.4249]\n",
      "E157 [D Loss: -159694.4062] [G loss: -15.4249]\n",
      "E158 [D Loss: -139657.2812] [G loss: -15.4249]\n",
      "E159 [D Loss: -149647.8281] [G loss: -15.4249]\n",
      "E160 [D Loss: -124499.5156] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['figpreserves', 'oil-curedblackolives', 'bicarbonateofsoda', 'dirtyricemix', 'chocolatewhippedcream', 'breadedchickennuggets', 'reduced-caloriemargarine', 'walleye', 'fatfreespaghettisauce', 'chocolateliqueur']\n",
      "E161 [D Loss: -138213.8125] [G loss: -15.4249]\n",
      "E162 [D Loss: -155076.3750] [G loss: -15.4249]\n",
      "E163 [D Loss: -141841.2344] [G loss: -15.4249]\n",
      "E164 [D Loss: -125956.2578] [G loss: -15.4249]\n",
      "E165 [D Loss: -161237.7500] [G loss: -15.4249]\n",
      "E166 [D Loss: -134343.4531] [G loss: -15.4249]\n",
      "E167 [D Loss: -182805.1875] [G loss: -15.4249]\n",
      "E168 [D Loss: -153436.5938] [G loss: -15.4249]\n",
      "E169 [D Loss: -130644.6719] [G loss: -15.4249]\n",
      "E170 [D Loss: -201829.4062] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['lemonthymeleaves', 'hotchickenstock', 'hotcocoa', 'greengiantwhiteandwildricewithfrenchstylegreenbeans', 'babycorn', 'babydillpickles', 'herbedcroutons', 'soymilk', 'italianparsley', 'chocolatecandymelts']\n",
      "E171 [D Loss: -173867.7344] [G loss: -15.4249]\n",
      "E172 [D Loss: -139083.0938] [G loss: -15.4249]\n",
      "E173 [D Loss: -164915.4375] [G loss: -15.4249]\n",
      "E174 [D Loss: -166190.5938] [G loss: -15.4249]\n",
      "E175 [D Loss: -141012.7812] [G loss: -15.4249]\n",
      "E176 [D Loss: -163832.3438] [G loss: -15.4249]\n",
      "E177 [D Loss: -193788.5781] [G loss: -15.4249]\n",
      "E178 [D Loss: -199163.4531] [G loss: -15.4249]\n",
      "E179 [D Loss: -144427.6562] [G loss: -15.4249]\n",
      "E180 [D Loss: -195707.6875] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['turkeystuffing', 'solidpackpumpkin', 'lemonvinaigrette', 'cinnamonbark', 'birdchile', 'crackercrumbs', 'yellowcakemix', 'hotchickenstock', 'oreocookiepiecrusts', 'frozenbeefburgerpatties']\n",
      "E181 [D Loss: -177815.6875] [G loss: -15.4249]\n",
      "E182 [D Loss: -167272.0625] [G loss: -15.4249]\n",
      "E183 [D Loss: -205703.1875] [G loss: -15.4249]\n",
      "E184 [D Loss: -206761.4375] [G loss: -15.4249]\n",
      "E185 [D Loss: -191725.2812] [G loss: -15.4249]\n",
      "E186 [D Loss: -194163.8125] [G loss: -15.4249]\n",
      "E187 [D Loss: -176754.0625] [G loss: -15.4249]\n",
      "E188 [D Loss: -204714.0938] [G loss: -15.4249]\n",
      "E189 [D Loss: -176090.0938] [G loss: -15.4249]\n",
      "E190 [D Loss: -214697.1562] [G loss: -15.4249]\n",
      "*** GENERATED RECIPE ***\n",
      "Ingredients: ['leangroundveal', 'fatfreespaghettisauce', '\"campbellscreamofchickensoup\"', 'stripsteaks', 'babycorn', 'chickenbreasttenders', 'portwine', 'pearbabyfood', 'almondfilling', 'peppermintleaves']\n",
      "E191 [D Loss: -202927.0000] [G loss: -15.4249]\n",
      "E192 [D Loss: -184206.2812] [G loss: -15.4249]\n",
      "E193 [D Loss: -201584.4062] [G loss: -15.4249]\n",
      "E194 [D Loss: -246713.9531] [G loss: -15.4249]\n",
      "E195 [D Loss: -216425.6250] [G loss: -15.4249]\n",
      "E196 [D Loss: -203744.6719] [G loss: -15.4249]\n",
      "E197 [D Loss: -218808.7812] [G loss: -15.4249]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d5de8c711034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_critic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d5de8c711034>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(X_train, X_test, epochs, batch_size, sample_interval, n_critic)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Use the GAN to generate \"fake\" recipes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mgenerated_recipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Get a sample of real recipes from data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2969\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2971\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2972\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def training(X_train, X_test, epochs=1, batch_size=32, sample_interval=10, n_critic=5):\n",
    "    # Get batch count\n",
    "    batch_per_epoch = int(X_train.shape[0] / batch_size)\n",
    "    \n",
    "    # Calculate number of training iterations\n",
    "    epochs *= batch_per_epoch\n",
    "    \n",
    "    # Get half batch size\n",
    "    half_batch = int(batch_size / 2)\n",
    "    \n",
    "    # Build GAN\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    gan = build_gan(generator, discriminator)\n",
    "    \n",
    "    # Training step\n",
    "    for e in range(1, epochs + 1):\n",
    "        # for _ in tqdm(range(batch_size)):\n",
    "            \n",
    "        # Train 'critic' more than generator\n",
    "        for _ in range(n_critic):\n",
    "            \n",
    "            # Random noise as an input to initialize the generator\n",
    "            noise = random_noise(half_batch)\n",
    "            # replace with Laplace?\n",
    "            # replace high% of noise with 0\n",
    "\n",
    "            # Use the GAN to generate \"fake\" recipes\n",
    "            generated_recipes = generator.predict(noise)\n",
    "\n",
    "            # Get a sample of real recipes from data\n",
    "            # real_recipes = X_train.loc[np.random.randint(low=0, high=X_train.shape[0], size=batch_size)]\n",
    "            real_recipes = X_train.sample(half_batch)\n",
    "\n",
    "            # Mix the real and fake data\n",
    "            X = np.concatenate([real_recipes, generated_recipes])\n",
    "\n",
    "            # Create labels for real and fake data\n",
    "            y_dis = np.ones(2 * half_batch)  # fake\n",
    "            y_dis[:half_batch] = -1.0          # real\n",
    "            # y_dis[batch_size:] = -1.0  # modification for Wasserstein\n",
    "\n",
    "            # Train the discriminator while generator is fixed\n",
    "            discriminator.trainable = True\n",
    "            d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "        # Fix the images generated by the generator as real\n",
    "        noise = random_noise(batch_size)\n",
    "        y_gen = -np.ones(batch_size)\n",
    "\n",
    "        # Train the generator (to have the discriminator label samples as valid)\n",
    "        discriminator.trainable = False\n",
    "        g_loss = gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "        # Output loss\n",
    "        print(f\"E{e} [D Loss: {d_loss:.4f}] [G loss: {g_loss:.4f}]\")\n",
    "            \n",
    "        # Display created recipes at a given epoch interval\n",
    "        if e % sample_interval == 0:\n",
    "            # Display recipe\n",
    "            display_recipe(e, generator)\n",
    "    \n",
    "    return generator, discriminator, gan\n",
    "\n",
    "\n",
    "generator, discriminator, gan = training(X_train, X_test, epochs=5000, batch_size=32, n_critic=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
